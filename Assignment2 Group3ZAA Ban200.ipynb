{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BAN200_project_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtnwEa9inmPt"
      },
      "outputs": [],
      "source": [
        "from numpy import array\n",
        "from keras_preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Documents\n",
        "\n",
        "mysent = ['do you comet to see me', 'Seneca is a good college', 'that is yours', 'Do you want dinner', 'do you like it', 'where are you from', 'thank you i am good', 'how dare you say that?', 'How are you', 'How is the weather', 'how is your pet', 'i am fine', 'i live in toronto', 'i have no dog']\n"
      ],
      "metadata": {
        "id": "LU32Il8JoXJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorize and define class labels\n",
        "\n",
        "mysentlabels = array([1,0, 0,1,1,1, 0,1,1,1,1,0,0,0])"
      ],
      "metadata": {
        "id": "z7W8ZUkEorWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding of documents\n",
        "\n",
        "myvocabsiz = 40                       # max number of different words\n",
        "encodsent = [one_hot(i, myvocabsiz) for i in mysent]     # Encoding\n",
        "print(encodsent)\n",
        "type(encodsent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHd3ut23o6tQ",
        "outputId": "d4d65551-7849-44cb-81b5-63149bfefe92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[17, 4, 9, 20, 36, 30], [34, 35, 10, 13, 19], [38, 35, 6], [17, 4, 9, 7], [17, 4, 20, 25], [28, 37, 4, 31], [30, 4, 9, 23, 13], [8, 26, 4, 3, 38], [8, 37, 4], [8, 35, 8, 26], [8, 35, 5, 26], [9, 23, 22], [9, 4, 22, 9], [9, 37, 30, 19]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding documents to mas length 5\n",
        "\n",
        "length = 5\n",
        "padmysent = pad_sequences(encodsent, maxlen = length, padding = 'pre')\n",
        "print(padmysent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFO3VuiXpQ5-",
        "outputId": "1f4da3ab-1c4d-4f10-e090-eca56cdbae16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4  9 20 36 30]\n",
            " [34 35 10 13 19]\n",
            " [ 0  0 38 35  6]\n",
            " [ 0 17  4  9  7]\n",
            " [ 0 17  4 20 25]\n",
            " [ 0 28 37  4 31]\n",
            " [30  4  9 23 13]\n",
            " [ 8 26  4  3 38]\n",
            " [ 0  0  8 37  4]\n",
            " [ 0  8 35  8 26]\n",
            " [ 0  8 35  5 26]\n",
            " [ 0  0  9 23 22]\n",
            " [ 0  9  4 22  9]\n",
            " [ 0  9 37 30 19]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building model\n",
        "\n",
        "mymodel = Sequential()             \n",
        "mymodel.add(Embedding(input_dim=myvocabsiz, output_dim = 8, input_length = length))\n",
        "mymodel.add(Flatten())          # input layer\n",
        "#mymodel.add(Dense(8, activation = 'sigmoid'))         # hidden layer\n",
        "mymodel.add(Dense(1, activation = 'sigmoid'))         # output layer\n",
        "mymodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "print(mymodel.summary())\n",
        "mymodel.fit(padmysent, mysentlabels, epochs = 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4CQYhylqudd",
        "outputId": "1a09412a-cc6f-4177-f1bb-601dd51a4deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_45 (Embedding)    (None, 5, 8)              320       \n",
            "                                                                 \n",
            " flatten_44 (Flatten)        (None, 40)                0         \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 361\n",
            "Trainable params: 361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.6998 - accuracy: 0.3571\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6973 - accuracy: 0.4286\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6947 - accuracy: 0.4286\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6921 - accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5714\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6871 - accuracy: 0.6429\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6846 - accuracy: 0.7143\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.7143\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6795 - accuracy: 0.7857\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6770 - accuracy: 0.8571\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6745 - accuracy: 0.9286\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6720 - accuracy: 0.9286\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6695 - accuracy: 0.9286\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6670 - accuracy: 0.9286\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6645 - accuracy: 0.9286\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6620 - accuracy: 0.9286\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6595 - accuracy: 0.9286\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6570 - accuracy: 0.9286\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6545 - accuracy: 0.9286\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6520 - accuracy: 0.9286\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6494 - accuracy: 0.9286\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6469 - accuracy: 0.9286\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6444 - accuracy: 0.9286\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6418 - accuracy: 0.9286\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6393 - accuracy: 0.9286\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6367 - accuracy: 0.9286\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6341 - accuracy: 0.9286\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6315 - accuracy: 0.9286\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6289 - accuracy: 0.9286\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6263 - accuracy: 0.9286\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6237 - accuracy: 0.9286\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6211 - accuracy: 0.9286\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6184 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6158 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6131 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6104 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6077 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6050 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6023 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5995 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5968 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5940 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5912 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5884 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5856 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5828 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5799 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5771 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5742 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5714 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5685 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5656 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5627 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5597 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5568 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5539 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5509 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5479 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5450 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5390 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5329 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5299 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5269 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5238 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5208 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5177 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5147 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5116 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5085 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5055 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5024 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4931 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4900 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4869 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4838 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4807 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4776 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4744 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4713 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4682 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4651 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4620 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4558 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4526 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4495 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4464 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4433 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4371 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4309 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4278 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4247 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4217 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8144094b50>"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting\n",
        "\n",
        "topredict = ['where are you from', 'are you willing to go', 'do you study in seneca', 'i am james', 'i am very proud of you', 'how tall are you', 'i am short']\n",
        "\n",
        "\n",
        "vocab_size = 40\n",
        "encoded = [one_hot(i, vocab_size) for i in topredict]\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6oft9gct7HY",
        "outputId": "d8341013-eb07-4d6e-f4cc-78fc40815e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[28, 37, 4, 31], [37, 4, 30, 20, 16], [17, 4, 38, 22, 34], [9, 23, 39], [9, 23, 3, 37, 30, 4], [8, 26, 37, 4], [9, 23, 17]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 5\n",
        "mypaded = pad_sequences(encoded, maxlen= max_length, padding='pre')\n",
        "print(mypaded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1RpWhaNtz9h",
        "outputId": "faaea2c4-8bc1-470d-c1bb-63e19cf374fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0 28 37  4 31]\n",
            " [37  4 30 20 16]\n",
            " [17  4 38 22 34]\n",
            " [ 0  0  9 23 39]\n",
            " [23  3 37 30  4]\n",
            " [ 0  8 26 37  4]\n",
            " [ 0  0  9 23 17]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = mymodel.predict(mypaded )\n",
        "print(ypred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEOsgRm4vPrf",
        "outputId": "77bbd3a0-16a3-4ff6-aa32-f4be210c682b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.7037643 ]\n",
            " [0.5486569 ]\n",
            " [0.47848997]\n",
            " [0.3926739 ]\n",
            " [0.58431274]\n",
            " [0.7117493 ]\n",
            " [0.3988344 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.around(ypred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "329jgObQvVFZ",
        "outputId": "08cd75e6-e5af-4af2-9c6c-f4f5eda49a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tDBCHjcdvcY1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}